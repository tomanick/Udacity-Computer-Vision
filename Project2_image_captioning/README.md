# Project2 Image Captioning

## Project overview
In this project, I will use the dataset of image-caption pairs to train a CNN-RNN model to automatically generate images from captions. The network is trained on the Microsoft Common Objects in COntext (MS COCO) dataset. The image captioning model is displayed below.

![image](https://github.com/tomanick/Udacity-Computer-Vision/blob/master/Project2_image_captioning/images/encoder-decoder.png)

## Project files
The project will be broken up into a few main parts in four Python notebooks:

Notebook 1 : Exploring the dataset and initialize the COCO API

Notebook 2 : Loading and pre-processing data from the COCO dataset. I will also design a CNN-RNN model for automatically generating image captions

Notebook 3 : Train CNN-RNN model

Notebook 4 : Using my trained model to generate captions for images in the test dataset

Model.py: The CNN-RNN architecture
